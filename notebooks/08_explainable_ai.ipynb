{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c546807",
   "metadata": {},
   "source": [
    "# Explainable AI Techniques\n",
    "## COMP647 Assignment 03\n",
    "### Student ID: 1163127\n",
    "\n",
    "This notebook implements explainability techniques for machine learning models:\n",
    "- Feature importance from tree-based models\n",
    "- Permutation importance\n",
    "- Decision tree visualization\n",
    "- Partial dependence plots\n",
    "\n",
    "These techniques help understand model decisions and build trust in predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed/accepted_sample_10000.csv')\n",
    "    print(f\"Data loaded: {df.shape}\")\n",
    "    \n",
    "    target_column = 'loan_status'\n",
    "    numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numerical_features = [c for c in numerical_features \n",
    "                         if c != target_column and not c.endswith('_id')][:15]\n",
    "    \n",
    "    X = df[numerical_features].fillna(df[numerical_features].mean())\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[target_column].fillna('Unknown'))\n",
    "    \n",
    "    if len(np.unique(y)) > 2:\n",
    "        y = (y == pd.Series(y).mode()[0]).astype(int)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Features: {len(numerical_features)}\")\n",
    "    print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "    print(\"Data prepared successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    X_train, X_test, y_train, y_test = None, None, None, None\n",
    "    numerical_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d699e",
   "metadata": {},
   "source": [
    "## Feature Importance from Random Forest\n",
    "Tree-based models provide built-in feature importance based on impurity decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest and extract feature importance\n",
    "if X_train is not None:\n",
    "    print(\"Training Random Forest for feature importance...\")\n",
    "    \n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': numerical_features,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    for idx, row in importance_df.head(10).iterrows():\n",
    "        print(f\"  {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = importance_df.head(15)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 15 Features by Random Forest Importance')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nFeature importance analysis complete\")\n",
    "else:\n",
    "    print(\"Cannot analyze - data not prepared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de81330e",
   "metadata": {},
   "source": [
    "## Permutation Importance\n",
    "Model-agnostic method that measures feature importance by randomly shuffling feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate permutation importance\n",
    "if X_train is not None:\n",
    "    print(\"Calculating permutation importance...\")\n",
    "    print(\"This may take a minute...\")\n",
    "    \n",
    "    # Calculate on test set\n",
    "    perm_importance = permutation_importance(\n",
    "        rf_model, X_test, y_test,\n",
    "        n_repeats=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame\n",
    "    perm_df = pd.DataFrame({\n",
    "        'feature': numerical_features,\n",
    "        'importance': perm_importance.importances_mean,\n",
    "        'std': perm_importance.importances_std\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Features by Permutation Importance:\")\n",
    "    for idx, row in perm_df.head(10).iterrows():\n",
    "        print(f\"  {row['feature']}: {row['importance']:.4f} (+/- {row['std']:.4f})\")\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = perm_df.head(15)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'],\n",
    "             xerr=top_features['std'], capsize=3)\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Permutation Importance')\n",
    "    plt.title('Top 15 Features by Permutation Importance\\n(with standard deviation)')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Compare with feature importance\n",
    "    print(\"\\n=== Comparison: Feature Importance vs Permutation Importance ===\")\n",
    "    comparison = pd.merge(\n",
    "        importance_df[['feature', 'importance']].rename(columns={'importance': 'RF_Importance'}),\n",
    "        perm_df[['feature', 'importance']].rename(columns={'importance': 'Perm_Importance'}),\n",
    "        on='feature'\n",
    "    ).head(10)\n",
    "    print(comparison.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nPermutation importance analysis complete\")\n",
    "else:\n",
    "    print(\"Cannot analyze - data not prepared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb236be",
   "metadata": {},
   "source": [
    "## Decision Tree Visualization\n",
    "Visualize a shallow decision tree to understand decision-making process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29dfdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and visualize decision tree\n",
    "if X_train is not None:\n",
    "    print(\"Training shallow decision tree for visualization...\")\n",
    "    \n",
    "    # Train a shallow tree (max_depth=3 for clarity)\n",
    "    tree_model = DecisionTreeClassifier(\n",
    "        max_depth=3,\n",
    "        random_state=42,\n",
    "        min_samples_split=20\n",
    "    )\n",
    "    \n",
    "    tree_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    train_acc = tree_model.score(X_train, y_train)\n",
    "    test_acc = tree_model.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"Tree Accuracy - Train: {train_acc:.4f}, Test: {test_acc:.4f}\")\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(\n",
    "        tree_model,\n",
    "        feature_names=numerical_features,\n",
    "        class_names=['Class 0', 'Class 1'],\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        fontsize=10\n",
    "    )\n",
    "    plt.title('Decision Tree Visualization (max_depth=3)\\nShows feature splits and decision rules')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nDecision tree visualization complete\")\n",
    "    print(\"Tree depth limited to 3 for interpretability\")\n",
    "else:\n",
    "    print(\"Cannot visualize - data not prepared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa89d8",
   "metadata": {},
   "source": [
    "## Partial Dependence Plots\n",
    "Show how predictions change when a feature varies while others are held constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46dca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create partial dependence plots\n",
    "if X_train is not None and len(importance_df) > 0:\n",
    "    print(\"Generating partial dependence plots...\")\n",
    "    print(\"Showing top 4 most important features...\")\n",
    "    \n",
    "    # Get top 4 features\n",
    "    top_4_features = importance_df.head(4)['feature'].tolist()\n",
    "    top_4_indices = [numerical_features.index(f) for f in top_4_features]\n",
    "    \n",
    "    # Create PDP\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    display = PartialDependenceDisplay.from_estimator(\n",
    "        rf_model,\n",
    "        X_train,\n",
    "        top_4_indices,\n",
    "        feature_names=numerical_features,\n",
    "        grid_resolution=20,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    plt.suptitle('Partial Dependence Plots for Top 4 Features', fontsize=14, y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nPartial dependence plots generated\")\n",
    "    print(\"These show how each feature affects predictions independently\")\n",
    "else:\n",
    "    print(\"Cannot generate - data not prepared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1115d",
   "metadata": {},
   "source": [
    "## Explainability Summary\n",
    "Key insights from all explainability techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary insights\n",
    "if X_train is not None:\n",
    "    print(\"=== Explainability Insights ===\\n\")\n",
    "    \n",
    "    print(\"1. Feature Importance (Random Forest):\")\n",
    "    print(f\"   Top feature: {importance_df.iloc[0]['feature']}\")\n",
    "    print(f\"   Importance: {importance_df.iloc[0]['importance']:.4f}\")\n",
    "    \n",
    "    print(\"\\n2. Permutation Importance:\")\n",
    "    print(f\"   Top feature: {perm_df.iloc[0]['feature']}\")\n",
    "    print(f\"   Importance: {perm_df.iloc[0]['importance']:.4f}\")\n",
    "    \n",
    "    print(\"\\n3. Model Interpretability:\")\n",
    "    print(\"   - Tree-based models: High interpretability with feature importance\")\n",
    "    print(\"   - Decision trees: Visual representation of decision rules\")\n",
    "    print(\"   - Partial dependence: Shows individual feature effects\")\n",
    "    \n",
    "    print(\"\\n4. Trust and Transparency:\")\n",
    "    print(\"   - Multiple explainability methods confirm feature rankings\")\n",
    "    print(\"   - Decision process is auditable and understandable\")\n",
    "    print(\"   - Stakeholders can verify model reasoning\")\n",
    "    \n",
    "    print(\"\\n=== Recommendations ===\")\n",
    "    print(\"For production deployment:\")\n",
    "    print(\"- Monitor top features for data drift\")\n",
    "    print(\"- Document feature importance in model cards\")\n",
    "    print(\"- Use decision trees for stakeholder communication\")\n",
    "    print(\"- Regularly update explainability analysis\")\n",
    "    \n",
    "else:\n",
    "    print(\"Summary not available - analysis incomplete\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
