{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Encoding Implementation\n",
    "# Based on LAB4 materials - efficient for high cardinality categorical features\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "def apply_binary_encoding(df, categorical_columns):\n",
    "    \"\"\"\n",
    "    Apply binary encoding for high cardinality categorical features\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with categorical features\n",
    "    categorical_columns: list of column names to encode\n",
    "    \n",
    "    Returns:\n",
    "    df_encoded: DataFrame with binary encoded features\n",
    "    encoder: fitted binary encoder for inverse transform\n",
    "    \"\"\"\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    print(\"Applying Binary Encoding...\")\n",
    "    print(\"Binary encoding reduces dimensionality compared to one-hot encoding\")\n",
    "    print(\"Example: 8 categories need only 3 binary columns (2^3 = 8)\")\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col in df_encoded.columns:\n",
    "            # Handle missing values\n",
    "            df_encoded[col] = df_encoded[col].fillna('Unknown')\n",
    "            \n",
    "            # Apply binary encoding\n",
    "            encoder = ce.BinaryEncoder(cols=[col])\n",
    "            encoded_cols = encoder.fit_transform(df_encoded[[col]])\n",
    "            \n",
    "            # Add encoded columns to dataframe\n",
    "            for encoded_col in encoded_cols.columns:\n",
    "                df_encoded[f\"{col}_bin_{encoded_col}\"] = encoded_cols[encoded_col]\n",
    "            \n",
    "            n_categories = df_encoded[col].nunique()\n",
    "            n_binary_cols = len(encoded_cols.columns)\n",
    "            print(f\"  {col}: {n_categories} categories -> {n_binary_cols} binary columns\")\n",
    "            \n",
    "            # Show the binary encoding pattern\n",
    "            if n_categories <= 8:  # Only show for small examples\n",
    "                unique_vals = df_encoded[col].unique()[:8]  # Show first 8\n",
    "                print(f\"    Encoding pattern for {col}:\")\n",
    "                for val in unique_vals:\n",
    "                    mask = df_encoded[col] == val\n",
    "                    if mask.any():\n",
    "                        binary_vals = encoded_cols[mask].iloc[0].values\n",
    "                        print(f\"      '{val}' -> {binary_vals}\")\n",
    "    \n",
    "    return df_encoded, encoder\n",
    "\n",
    "# Example usage with high cardinality categorical features\n",
    "if not df.empty and categorical_features:\n",
    "    # Find features with high cardinality (good candidates for binary encoding)\n",
    "    high_cardinality_features = []\n",
    "    for col in categorical_features:\n",
    "        if col in df.columns:\n",
    "            n_unique = df[col].nunique()\n",
    "            if 5 < n_unique <= 50:  # Good range for binary encoding\n",
    "                high_cardinality_features.append(col)\n",
    "    \n",
    "    if high_cardinality_features:\n",
    "        # Take first feature for demonstration\n",
    "        demo_feature = high_cardinality_features[0]\n",
    "        print(f\"Demonstrating Binary Encoding on: {demo_feature}\")\n",
    "        print(f\"  Unique values: {df[demo_feature].nunique()}\")\n",
    "        \n",
    "        df_binary_encoded, binary_encoder = apply_binary_encoding(df, [demo_feature])\n",
    "        \n",
    "        # Show comparison of dimensions\n",
    "        binary_cols = [c for c in df_binary_encoded.columns if c.startswith(demo_feature + '_bin_')]\n",
    "        print(f\"\\nDimensionality comparison:\")\n",
    "        print(f\"  One-hot would create: {df[demo_feature].nunique()} columns\")  \n",
    "        print(f\"  Binary encoding creates: {len(binary_cols)} columns\")\n",
    "        print(f\"  Space savings: {((df[demo_feature].nunique() - len(binary_cols)) / df[demo_feature].nunique() * 100):.1f}%\")\n",
    "    else:\n",
    "        print(\"No suitable high cardinality features found for Binary Encoding demonstration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling Implementation  \n",
    "# Based on LAB4 materials - scales features to mean=0, std=1\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def apply_standard_scaling(df, numerical_columns):\n",
    "    \"\"\"\n",
    "    Apply Standard scaling (Z-score normalization) to numerical features\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with numerical features\n",
    "    numerical_columns: list of column names to scale\n",
    "    \n",
    "    Returns:\n",
    "    df_scaled: DataFrame with standardized features\n",
    "    scaler: fitted StandardScaler for inverse transform\n",
    "    \"\"\"\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    print(\"Applying Standard Scaling...\")\n",
    "    print(\"Standardizing numerical features to mean=0, std=1\")\n",
    "    \n",
    "    if numerical_columns:\n",
    "        # Initialize scaler\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Select only numerical columns that exist in dataframe\n",
    "        valid_columns = [col for col in numerical_columns if col in df_scaled.columns]\n",
    "        \n",
    "        if valid_columns:\n",
    "            # Apply scaling\n",
    "            df_scaled[valid_columns] = scaler.fit_transform(df_scaled[valid_columns])\n",
    "            \n",
    "            print(f\"Standardized {len(valid_columns)} numerical features:\")\n",
    "            for col in valid_columns[:5]:  # Show first 5 features\n",
    "                original_mean = df[col].mean()\n",
    "                original_std = df[col].std()\n",
    "                scaled_mean = df_scaled[col].mean()\n",
    "                scaled_std = df_scaled[col].std()\n",
    "                print(f\"  {col}: mean {original_mean:.2f}±{original_std:.2f} -> {scaled_mean:.2f}±{scaled_std:.2f}\")\n",
    "            \n",
    "            if len(valid_columns) > 5:\n",
    "                print(f\"  ... and {len(valid_columns) - 5} more features\")\n",
    "        else:\n",
    "            print(\"No valid numerical columns found for scaling\")\n",
    "            scaler = None\n",
    "    else:\n",
    "        print(\"No numerical columns provided for scaling\")\n",
    "        scaler = None\n",
    "    \n",
    "    return df_scaled, scaler\n",
    "\n",
    "# Compare scaling methods side by side\n",
    "if not df.empty and numerical_features:\n",
    "    # Select same features as Min-Max scaling for comparison\n",
    "    sample_numerical = []\n",
    "    for col in numerical_features[:10]:\n",
    "        if col in df.columns and not col.lower().endswith('_id'):\n",
    "            if df[col].nunique() > 2:\n",
    "                sample_numerical.append(col)\n",
    "    \n",
    "    if sample_numerical:\n",
    "        print(f\"Demonstrating Standard Scaling on: {len(sample_numerical)} features\")\n",
    "        df_standard_scaled, standard_scaler = apply_standard_scaling(df, sample_numerical)\n",
    "        \n",
    "        # Scaling comparison visualization\n",
    "        if len(sample_numerical) >= 1:\n",
    "            comparison_feature = sample_numerical[0]\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            # Original distribution\n",
    "            axes[0].hist(df[comparison_feature].dropna(), bins=30, alpha=0.7, color='blue')\n",
    "            axes[0].set_title(f'Original: {comparison_feature}')\n",
    "            axes[0].set_xlabel('Value')\n",
    "            axes[0].set_ylabel('Frequency')\n",
    "            \n",
    "            # Min-Max scaled\n",
    "            if 'df_minmax_scaled' in locals():\n",
    "                axes[1].hist(df_minmax_scaled[comparison_feature].dropna(), bins=30, alpha=0.7, color='red')\n",
    "                axes[1].set_title(f'Min-Max Scaled: {comparison_feature}')\n",
    "                axes[1].set_xlabel('Scaled Value [0,1]')\n",
    "                axes[1].set_ylabel('Frequency')\n",
    "            \n",
    "            # Standard scaled\n",
    "            axes[2].hist(df_standard_scaled[comparison_feature].dropna(), bins=30, alpha=0.7, color='green')\n",
    "            axes[2].set_title(f'Standard Scaled: {comparison_feature}')\n",
    "            axes[2].set_xlabel('Standardized Value')\n",
    "            axes[2].set_ylabel('Frequency')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Show scaling statistics\n",
    "            print(f\"\\nScaling Statistics for {comparison_feature}:\")\n",
    "            print(f\"Original: mean={df[comparison_feature].mean():.2f}, std={df[comparison_feature].std():.2f}\")\n",
    "            if 'df_minmax_scaled' in locals():\n",
    "                print(f\"Min-Max:  min={df_minmax_scaled[comparison_feature].min():.2f}, max={df_minmax_scaled[comparison_feature].max():.2f}\")\n",
    "            print(f\"Standard: mean={df_standard_scaled[comparison_feature].mean():.2f}, std={df_standard_scaled[comparison_feature].std():.2f}\")\n",
    "    else:\n",
    "        print(\"No suitable numerical features found for Standard Scaling demonstration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaling Implementation\n",
    "# Based on LAB4 materials - scales features to range [0, 1]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def apply_minmax_scaling(df, numerical_columns, feature_range=(0, 1)):\n",
    "    \"\"\"\n",
    "    Apply Min-Max scaling to numerical features\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with numerical features\n",
    "    numerical_columns: list of column names to scale\n",
    "    feature_range: tuple defining the target range (default: (0, 1))\n",
    "    \n",
    "    Returns:\n",
    "    df_scaled: DataFrame with scaled features\n",
    "    scaler: fitted MinMaxScaler for inverse transform\n",
    "    \"\"\"\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    print(\"Applying Min-Max Scaling...\")\n",
    "    print(f\"Scaling numerical features to range {feature_range}\")\n",
    "    \n",
    "    if numerical_columns:\n",
    "        # Initialize scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        \n",
    "        # Select only numerical columns that exist in dataframe\n",
    "        valid_columns = [col for col in numerical_columns if col in df_scaled.columns]\n",
    "        \n",
    "        if valid_columns:\n",
    "            # Apply scaling\n",
    "            df_scaled[valid_columns] = scaler.fit_transform(df_scaled[valid_columns])\n",
    "            \n",
    "            print(f\"Scaled {len(valid_columns)} numerical features:\")\n",
    "            for col in valid_columns[:5]:  # Show first 5 features\n",
    "                original_min = df[col].min()\n",
    "                original_max = df[col].max()\n",
    "                scaled_min = df_scaled[col].min()\n",
    "                scaled_max = df_scaled[col].max()\n",
    "                print(f\"  {col}: [{original_min:.2f}, {original_max:.2f}] -> [{scaled_min:.2f}, {scaled_max:.2f}]\")\n",
    "            \n",
    "            if len(valid_columns) > 5:\n",
    "                print(f\"  ... and {len(valid_columns) - 5} more features\")\n",
    "        else:\n",
    "            print(\"No valid numerical columns found for scaling\")\n",
    "            scaler = None\n",
    "    else:\n",
    "        print(\"No numerical columns provided for scaling\")\n",
    "        scaler = None\n",
    "    \n",
    "    return df_scaled, scaler\n",
    "\n",
    "# Example usage with sample numerical features\n",
    "if not df.empty and numerical_features:\n",
    "    # Select a subset of numerical features for demonstration\n",
    "    # Exclude ID columns and binary features\n",
    "    sample_numerical = []\n",
    "    for col in numerical_features[:10]:  # Take first 10 numerical features\n",
    "        if col in df.columns and not col.lower().endswith('_id'):\n",
    "            # Check if feature has reasonable range (not binary 0/1)\n",
    "            if df[col].nunique() > 2:\n",
    "                sample_numerical.append(col)\n",
    "    \n",
    "    if sample_numerical:\n",
    "        print(f\"Demonstrating Min-Max Scaling on: {len(sample_numerical)} features\")\n",
    "        df_minmax_scaled, minmax_scaler = apply_minmax_scaling(df, sample_numerical)\n",
    "        \n",
    "        # Show comparison of original vs scaled distributions\n",
    "        if len(sample_numerical) >= 2:\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "            \n",
    "            # Plot first two features for comparison\n",
    "            for i, col in enumerate(sample_numerical[:2]):\n",
    "                # Original distribution\n",
    "                axes[i, 0].hist(df[col].dropna(), bins=30, alpha=0.7, color='blue')\n",
    "                axes[i, 0].set_title(f'Original: {col}')\n",
    "                axes[i, 0].set_xlabel('Value')\n",
    "                axes[i, 0].set_ylabel('Frequency')\n",
    "                \n",
    "                # Scaled distribution\n",
    "                axes[i, 1].hist(df_minmax_scaled[col].dropna(), bins=30, alpha=0.7, color='red')\n",
    "                axes[i, 1].set_title(f'Min-Max Scaled: {col}')\n",
    "                axes[i, 1].set_xlabel('Scaled Value')\n",
    "                axes[i, 1].set_ylabel('Frequency')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No suitable numerical features found for Min-Max Scaling demonstration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding Implementation\n",
    "# Based on LAB4 materials - safe for linear models, avoids ordinal assumptions\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def apply_onehot_encoding(df, categorical_columns, drop_first=True, max_categories=10):\n",
    "    \"\"\"\n",
    "    Apply one-hot encoding to categorical features\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with categorical features  \n",
    "    categorical_columns: list of column names to encode\n",
    "    drop_first: whether to drop first category to avoid multicollinearity\n",
    "    max_categories: maximum unique values to consider for encoding\n",
    "    \n",
    "    Returns:\n",
    "    df_encoded: DataFrame with one-hot encoded features\n",
    "    \"\"\"\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    print(\"Applying One-Hot Encoding...\")\n",
    "    for col in categorical_columns:\n",
    "        if col in df_encoded.columns:\n",
    "            # Check if feature has reasonable number of categories\n",
    "            n_categories = df_encoded[col].nunique()\n",
    "            \n",
    "            if n_categories <= max_categories:\n",
    "                # Apply one-hot encoding using pandas get_dummies\n",
    "                # This is more memory efficient than sklearn OneHotEncoder for small datasets\n",
    "                dummies = pd.get_dummies(df_encoded[col], prefix=col, drop_first=drop_first)\n",
    "                \n",
    "                # Add dummy columns to dataframe\n",
    "                df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "                \n",
    "                print(f\"  {col}: {n_categories} categories -> {len(dummies.columns)} dummy columns\")\n",
    "            else:\n",
    "                print(f\"  {col}: Skipped ({n_categories} categories > {max_categories} threshold)\")\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "# Example usage with sample categorical features\n",
    "if not df.empty and categorical_features:\n",
    "    # Select categorical features with reasonable number of categories\n",
    "    suitable_features = []\n",
    "    for col in categorical_features[:3]:\n",
    "        if col in df.columns and df[col].nunique() <= 10:\n",
    "            suitable_features.append(col)\n",
    "    \n",
    "    if suitable_features:\n",
    "        print(f\"Demonstrating One-Hot Encoding on: {suitable_features}\")\n",
    "        df_onehot_encoded = apply_onehot_encoding(df, suitable_features)\n",
    "        \n",
    "        # Show the new dummy columns created\n",
    "        for col in suitable_features:\n",
    "            dummy_cols = [c for c in df_onehot_encoded.columns if c.startswith(col + '_')]\n",
    "            if dummy_cols:\n",
    "                print(f\"\\n{col} dummy columns: {dummy_cols}\")\n",
    "                print(f\"Sample values:\")\n",
    "                print(df_onehot_encoded[dummy_cols].head())\n",
    "    else:\n",
    "        print(\"No suitable categorical features found for One-Hot Encoding demonstration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding Implementation\n",
    "# Based on LAB4 materials - simple encoding for binary/ordinal categorical variables\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def apply_label_encoding(df, categorical_columns):\n",
    "    \"\"\"\n",
    "    Apply label encoding to categorical features\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with categorical features\n",
    "    categorical_columns: list of column names to encode\n",
    "    \n",
    "    Returns:\n",
    "    df_encoded: DataFrame with label encoded features\n",
    "    encoders: dict of fitted encoders for inverse transform\n",
    "    \"\"\"\n",
    "    df_encoded = df.copy()\n",
    "    encoders = {}\n",
    "    \n",
    "    print(\"Applying Label Encoding...\")\n",
    "    for col in categorical_columns:\n",
    "        if col in df_encoded.columns:\n",
    "            # Create and fit encoder\n",
    "            le = LabelEncoder()\n",
    "            # Handle missing values by filling with 'Unknown'\n",
    "            df_encoded[col] = df_encoded[col].fillna('Unknown')\n",
    "            df_encoded[col + '_encoded'] = le.fit_transform(df_encoded[col])\n",
    "            \n",
    "            # Store encoder for later use\n",
    "            encoders[col] = le\n",
    "            \n",
    "            print(f\"  {col}: {len(le.classes_)} unique values -> 0 to {len(le.classes_)-1}\")\n",
    "    \n",
    "    return df_encoded, encoders\n",
    "\n",
    "# Example usage with sample categorical features\n",
    "if not df.empty and categorical_features:\n",
    "    # Select a few categorical features for demonstration\n",
    "    sample_categorical = categorical_features[:3] if len(categorical_features) >= 3 else categorical_features\n",
    "    \n",
    "    print(f\"Demonstrating Label Encoding on: {sample_categorical}\")\n",
    "    df_label_encoded, label_encoders = apply_label_encoding(df, sample_categorical)\n",
    "    \n",
    "    # Show before and after comparison\n",
    "    for col in sample_categorical:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col} - Original vs Encoded:\")\n",
    "            comparison = pd.DataFrame({\n",
    "                'Original': df[col].head(10),\n",
    "                'Encoded': df_label_encoded[col + '_encoded'].head(10)\n",
    "            })\n",
    "            print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Lending Club Data\n",
    "## COMP647 Assignment 03\n",
    "### Student ID: 1163127\n",
    "\n",
    "This notebook implements feature engineering techniques including:\n",
    "- Data loading and initial exploration\n",
    "- Categorical encoding methods\n",
    "- Feature scaling techniques\n",
    "\n",
    "Based on LAB4 materials and course teachings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data from Assignment 02\n",
    "try:\n",
    "    # Load the processed sample data\n",
    "    df = pd.read_csv('../data/processed/accepted_sample_10000.csv')\n",
    "    print(f\"Data loaded successfully: {df.shape}\")\n",
    "    print(f\"Columns: {len(df.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Processed data not found. Please run Assignment 02 notebooks first.\")\n",
    "    # For demonstration, create sample data structure\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "# Display basic info about the dataset\n",
    "if not df.empty:\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    # Identify categorical and numerical features\n",
    "    categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    print(f\"\\nCategorical features: {len(categorical_features)}\")\n",
    "    print(f\"Numerical features: {len(numerical_features)}\")\n",
    "    \n",
    "    if categorical_features:\n",
    "        print(\"\\nSample categorical features:\")\n",
    "        for col in categorical_features[:5]:  # Show first 5\n",
    "            print(f\"  {col}: {df[col].nunique()} unique values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
