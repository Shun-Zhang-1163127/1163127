{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10365ef9",
   "metadata": {},
   "source": [
    "# Feature Selection for Lending Club Data\n",
    "## COMP647 Assignment 03\n",
    "### Student ID: 1163127\n",
    "\n",
    "This notebook implements feature selection techniques including:\n",
    "- Univariate statistical tests (ANOVA, Chi-Square)\n",
    "- Wrapper methods (Recursive Feature Elimination)\n",
    "- Embedded methods (Random Forest importance)\n",
    "\n",
    "Based on LAB5 materials and course teachings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Feature selection libraries\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, f_classif, chi2, \n",
    "    RFE, RFECV,\n",
    "    SelectFromModel\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data from previous notebooks\n",
    "try:\n",
    "    # Load the processed sample data\n",
    "    df = pd.read_csv('../data/processed/accepted_sample_10000.csv')\n",
    "    print(f\"Data loaded successfully: {df.shape}\")\n",
    "    print(f\"Columns: {len(df.columns)}\")\n",
    "    \n",
    "    # Display basic info\n",
    "    print(\"\\nDataset Preview:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Identify target variable\n",
    "    target_column = 'loan_status' if 'loan_status' in df.columns else None\n",
    "    if target_column:\n",
    "        print(f\"\\nTarget variable: {target_column}\")\n",
    "        print(f\"Target distribution:\")\n",
    "        print(df[target_column].value_counts())\n",
    "    else:\n",
    "        print(\"\\nWarning: loan_status column not found\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Processed data not found. Please run Assignment 02 notebooks first.\")\n",
    "    df = pd.DataFrame()\n",
    "    target_column = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132372fd",
   "metadata": {},
   "source": [
    "## Univariate Statistical Tests\n",
    "### ANOVA F-test for Numerical Features\n",
    "Based on LAB5 materials - measures linear dependency between features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0349034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA F-test Implementation\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "def apply_anova_ftest(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Apply ANOVA F-test for feature selection\n",
    "    \n",
    "    Parameters:\n",
    "    X: DataFrame with numerical features\n",
    "    y: target variable (classification)\n",
    "    k: number of top features to select\n",
    "    \n",
    "    Returns:\n",
    "    selected_features, results_df, selector\n",
    "    \"\"\"\n",
    "    print(\"Applying ANOVA F-test for numerical features...\")\n",
    "    \n",
    "    selector = SelectKBest(score_func=f_classif, k=min(k, X.shape[1]))\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "    # Get results\n",
    "    results_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'f_score': selector.scores_,\n",
    "        'selected': selector.get_support()\n",
    "    }).sort_values('f_score', ascending=False)\n",
    "    \n",
    "    selected_features = results_df[results_df['selected']]['feature'].tolist()\n",
    "    \n",
    "    print(f\"Selected {len(selected_features)} features\")\n",
    "    print(\"\\nTop 5 features:\")\n",
    "    for idx, row in results_df.head(5).iterrows():\n",
    "        print(f\"  {row['feature']}: F-score = {row['f_score']:.2f}\")\n",
    "    \n",
    "    return selected_features, results_df, selector\n",
    "\n",
    "# Apply ANOVA if data is available\n",
    "if not df.empty and target_column:\n",
    "    # Get numerical features\n",
    "    num_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    num_features = [c for c in num_features if c != target_column and not c.endswith('_id')]\n",
    "    \n",
    "    if len(num_features) >= 5:\n",
    "        X_num = df[num_features].fillna(df[num_features].mean())\n",
    "        \n",
    "        # Prepare target\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(df[target_column].fillna('Unknown'))\n",
    "        \n",
    "        # Apply ANOVA\n",
    "        sel_anova, anova_results, anova_sel = apply_anova_ftest(X_num, y, k=10)\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        top15 = anova_results.head(15)\n",
    "        plt.bar(range(len(top15)), top15['f_score'])\n",
    "        plt.xticks(range(len(top15)), top15['feature'], rotation=45, ha='right')\n",
    "        plt.title('Top 15 Features - ANOVA F-test')\n",
    "        plt.ylabel('F-Score')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Not enough numerical features for ANOVA\")\n",
    "        sel_anova = []\n",
    "else:\n",
    "    print(\"No data for ANOVA demo\")\n",
    "    sel_anova = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73211b16",
   "metadata": {},
   "source": [
    "### Chi-Square Test for Categorical Features\n",
    "Based on LAB5 materials - measures dependency between categorical features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf254f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Square Test Implementation\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def apply_chi_square(X, y, k=5):\n",
    "    \"\"\"Apply Chi-Square test for categorical features\"\"\"\n",
    "    print(\"Applying Chi-Square test for categorical features...\")\n",
    "    \n",
    "    selector = SelectKBest(score_func=chi2, k=min(k, X.shape[1]))\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'chi2_score': selector.scores_,\n",
    "        'selected': selector.get_support()\n",
    "    }).sort_values('chi2_score', ascending=False)\n",
    "    \n",
    "    selected_features = results_df[results_df['selected']]['feature'].tolist()\n",
    "    \n",
    "    print(f\"Selected {len(selected_features)} features\")\n",
    "    print(\"\\nTop features:\")\n",
    "    for idx, row in results_df.head(5).iterrows():\n",
    "        print(f\"  {row['feature']}: Chi2 = {row['chi2_score']:.2f}\")\n",
    "    \n",
    "    return selected_features, results_df, selector\n",
    "\n",
    "# Apply Chi-Square if data available\n",
    "if not df.empty and target_column:\n",
    "    cat_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    if target_column in cat_features:\n",
    "        cat_features.remove(target_column)\n",
    "    \n",
    "    if len(cat_features) >= 3:\n",
    "        # Encode categorical features\n",
    "        X_cat = df[cat_features[:10]].copy()\n",
    "        for col in X_cat.columns:\n",
    "            le = LabelEncoder()\n",
    "            X_cat[col] = le.fit_transform(X_cat[col].fillna('Unknown'))\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(df[target_column].fillna('Unknown'))\n",
    "        \n",
    "        sel_chi, chi_results, chi_sel = apply_chi_square(X_cat, y, k=5)\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        top10 = chi_results.head(10)\n",
    "        plt.bar(range(len(top10)), top10['chi2_score'])\n",
    "        plt.xticks(range(len(top10)), top10['feature'], rotation=45, ha='right')\n",
    "        plt.title('Top 10 Features - Chi-Square Test')\n",
    "        plt.ylabel('Chi-Square Score')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Not enough categorical features\")\n",
    "        sel_chi = []\n",
    "else:\n",
    "    sel_chi = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b8174",
   "metadata": {},
   "source": [
    "## Wrapper Methods\n",
    "### Recursive Feature Elimination (RFE)\n",
    "Backward elimination using model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE Implementation\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "def apply_rfe(X, y, n_features=10):\n",
    "    \"\"\"Apply Recursive Feature Elimination\"\"\"\n",
    "    print(\"Applying RFE with Logistic Regression...\")\n",
    "    \n",
    "    estimator = LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')\n",
    "    selector = RFE(estimator, n_features_to_select=min(n_features, X.shape[1]), step=1)\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "    rankings = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'ranking': selector.ranking_,\n",
    "        'selected': selector.get_support()\n",
    "    }).sort_values('ranking')\n",
    "    \n",
    "    selected = rankings[rankings['selected']]['feature'].tolist()\n",
    "    \n",
    "    print(f\"Selected {len(selected)} features\")\n",
    "    print(\"\\nSelected features:\")\n",
    "    for f in selected[:5]:\n",
    "        print(f\"  {f}\")\n",
    "    \n",
    "    return selected, rankings, selector\n",
    "\n",
    "# Apply RFE\n",
    "if not df.empty and target_column:\n",
    "    num_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    num_features = [c for c in num_features if c != target_column and not c.endswith('_id')]\n",
    "    \n",
    "    if len(num_features) >= 5:\n",
    "        X_rfe = df[num_features[:15]].fillna(df[num_features[:15]].mean())\n",
    "        scaler = StandardScaler()\n",
    "        X_rfe = pd.DataFrame(scaler.fit_transform(X_rfe), columns=X_rfe.columns)\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(df[target_column].fillna('Unknown'))\n",
    "        if len(np.unique(y)) > 2:\n",
    "            y = (y == y[0]).astype(int)\n",
    "        \n",
    "        sel_rfe, rfe_rank, rfe_sel = apply_rfe(X_rfe, y, n_features=8)\n",
    "        \n",
    "        # Visualize rankings\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(range(len(rfe_rank)), rfe_rank['ranking'])\n",
    "        plt.xticks(range(len(rfe_rank)), rfe_rank['feature'], rotation=45, ha='right')\n",
    "        plt.title('Feature Rankings - RFE (1=best)')\n",
    "        plt.ylabel('Ranking')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        sel_rfe = []\n",
    "else:\n",
    "    sel_rfe = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8747a0b6",
   "metadata": {},
   "source": [
    "## Embedded Methods\n",
    "### Random Forest Feature Importance\n",
    "Model-based selection using impurity decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Feature Importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def apply_rf_importance(X, y, n_features=10):\n",
    "    \"\"\"Apply Random Forest feature selection\"\"\"\n",
    "    print(\"Applying Random Forest feature importance...\")\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    selected = importance_df.head(n_features)['feature'].tolist()\n",
    "    \n",
    "    print(f\"Selected {len(selected)} features\")\n",
    "    print(\"\\nTop features:\")\n",
    "    for idx, row in importance_df.head(5).iterrows():\n",
    "        print(f\"  {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    return selected, importance_df, rf\n",
    "\n",
    "# Apply Random Forest\n",
    "if not df.empty and target_column:\n",
    "    num_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    num_features = [c for c in num_features if c != target_column and not c.endswith('_id')]\n",
    "    \n",
    "    if len(num_features) >= 5:\n",
    "        X_rf = df[num_features[:15]].fillna(df[num_features[:15]].mean())\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(df[target_column].fillna('Unknown'))\n",
    "        if len(np.unique(y)) > 2:\n",
    "            y = (y == y[0]).astype(int)\n",
    "        \n",
    "        sel_rf, rf_imp, rf_model = apply_rf_importance(X_rf, y, n_features=10)\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        top15 = rf_imp.head(15)\n",
    "        plt.barh(range(len(top15)), top15['importance'])\n",
    "        plt.yticks(range(len(top15)), top15['feature'])\n",
    "        plt.title('Top 15 Features - Random Forest Importance')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        sel_rf = []\n",
    "else:\n",
    "    sel_rf = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda9b977",
   "metadata": {},
   "source": [
    "## Comparison of Methods\n",
    "Compare results from different feature selection approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all methods\n",
    "print(\"=== Feature Selection Methods Comparison ===\\n\")\n",
    "\n",
    "methods_summary = []\n",
    "\n",
    "if sel_anova:\n",
    "    methods_summary.append({'Method': 'ANOVA F-test', \n",
    "                           'Count': len(sel_anova),\n",
    "                           'Top_3': ', '.join(sel_anova[:3])})\n",
    "\n",
    "if sel_chi:\n",
    "    methods_summary.append({'Method': 'Chi-Square', \n",
    "                           'Count': len(sel_chi),\n",
    "                           'Top_3': ', '.join(sel_chi[:3])})\n",
    "\n",
    "if sel_rfe:\n",
    "    methods_summary.append({'Method': 'RFE', \n",
    "                           'Count': len(sel_rfe),\n",
    "                           'Top_3': ', '.join(sel_rfe[:3])})\n",
    "\n",
    "if sel_rf:\n",
    "    methods_summary.append({'Method': 'Random Forest', \n",
    "                           'Count': len(sel_rf),\n",
    "                           'Top_3': ', '.join(sel_rf[:3])})\n",
    "\n",
    "if methods_summary:\n",
    "    summary_df = pd.DataFrame(methods_summary)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n=== Recommendations ===\")\n",
    "    print(\"ANOVA F-test: Best for linear relationships (numerical features)\")\n",
    "    print(\"Chi-Square: Best for categorical features\")\n",
    "    print(\"RFE: Considers feature interactions\")\n",
    "    print(\"Random Forest: Captures non-linear patterns\")\n",
    "    print(\"\\nBest practice: Combine multiple methods for robust selection\")\n",
    "else:\n",
    "    print(\"No methods completed successfully\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
